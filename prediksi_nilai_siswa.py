# -*- coding: utf-8 -*-
"""prediksi_nilai_siswa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fZV9RPmoZt8KdOx506A6rSlcoVQzx6ef

# Proyek Machine Learning : Predictive Analytics

* Domain : Pendidikan
* Tujuan : Melakukan prediksi performa siswa di pendidikan menengah di dua sekolah Portugis
* Dataset yang digunakan : https://archive.ics.uci.edu/dataset/320/student+performance

### Install *package* ucimlrepo
"""

!pip install ucimlrepo

"""Perintah ini digunakan untuk menginstal paket Python ucimlrepo. Paket ini memberikan akses untuk dataset dari UCI Machine Learning Repository.

### Import Library yang diperlukan
"""

from ucimlrepo import fetch_ucirepo

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
import numpy as np
import warnings
import pickle
import pydotplus

from sklearn.linear_model import (
    LinearRegression,
    Ridge,
    Lasso,
    LogisticRegression,
    SGDClassifier,
    BayesianRidge,
)
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn import tree
from six import StringIO
from IPython.display import Image
from sklearn.ensemble import (
    RandomForestRegressor,
    RandomForestClassifier,
)
from sklearn.svm import LinearSVC
from numpy.ma.core import sqrt
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split
from numpy.polynomial.polynomial import polyfit
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    mean_squared_error,
    r2_score,
    mean_absolute_error,
    confusion_matrix
)
# Suppress FutureWarnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""Kode di atas digunakan untuk mengimpor berbagai pustaka dan modul Python yang  digunakan dalam proyek ini

## DATA UNDERSTANDING

### Load Dataset
"""

# fetch dataset
student_performance = fetch_ucirepo(id=320)

# data (as pandas dataframes)
X = student_performance.data.features
y = student_performance.data.targets

"""Fungsi ini digunakan untuk mengunduh dataset dari UCI Machine Learning Repository, dan memuat dataset ke dalam dua variabel X dan y, dimana X digunakan untuk data pelatihan model (variabel independen), dan y adalah nilai yang akan diprediksi oleh model berdasarkan X (variabel dependen atau label)

### Melihat ukuran Dataframe
"""

print(X.shape)
print(y.shape)

"""Kode ini berfungsi untuk menampilkan dimensi dari dua objek data yang berbeda, yaitu `X (fitur)` dan `y (target)`. Fungsi shape digunakan untuk mendapatkan informasi tentang ukuran atau bentuk (dimensi) dari array atau dataframe :
1. `X.shape` memiliki 649 baris (siswa) dan 30 kolom (fitur) yang mendeskripsikan berbagai atribut siswa yang dapat digunakan untuk memprediksi target.
2. `y.shape` memiliki 649 baris yang sesuai dengan jumlah siswa dan 3 kolom target. Setiap kolom target mewakili nilai siswa pada berbagai mata pelajaran yang akan diprediksi.

### Gabungkan Dataframe Fitur dan Target
"""

df = pd.concat([X, y], axis=1)

"""Tujuan dari kode ini adalah menggabungkan dua DataFrame, yaitu X (fitur) dan y (target), menjadi satu DataFrame

# Exploratory Data Analysis-Deskripsi Variabel

### Menampilkan tipe data setiap kolom pada dataset "df"
"""

df.info()

"""Dataset ini memiliki 649 entri dan 33 kolom, dengan 16 kolom berisi data numerik (tipe int64) dan 17 kolom lainnya berisi data kategorikal (tipe object). Semua kolom dalam dataset tidak memiliki nilai yang hilang, yang ditunjukkan oleh **649 non-null entries** pada setiap kolom. Kolom-kolom numerik seperti age, Medu, dan nilai ujian (G1, G2, G3) dapat langsung digunakan untuk analisis atau modeling, sementara kolom-kolom kategorikal seperti school, sex, dan address perlu diproses lebih lanjut menggunakan teknik encoding agar dapat digunakan dalam model machine learning. Ukuran memori yang digunakan oleh dataset adalah sekitar 167.4 KB.

## Deskripsi Variabel Numerik
"""

df.describe()

"""Hasil dari deskripsi varible numerik ini dapat kita lihat semua data memiliki jumlah kolom dengan jumlah 649 entri yang valid tanpa nilai yang hilang, yang ditunjukkan oleh nilai count yang sama untuk semua kolom. Rata-rata usia siswa yang mencapai 16.74 tahun, sementara rata-rata nilai ujian (G1, G2, G3) berkisar antara 11.4 hingga 11.9. Nilai deviasi standar (std) menunjukkan sebaran data, misalnya, deviasi standar untuk kolom age adalah 1.22, yang berarti sebagian besar usia siswa berada di sekitar rata-rata dengan variasi yang relatif kecil. Nilai min dan max menunjukkan rentang nilai, dengan usia siswa yang berada antara 15 hingga 22 tahun, sedangkan nilai ujian dapat bervariasi dari 0 hingga 19. Selain itu, kuartil data yang mencakup 25%, 50%, dan 75% memberikan gambaran lebih mendetail tentang distribusi nilai pada fitur-fitur tersebut. Secara keseluruhan, hasil ini menginformasikan distribusi dan rentang nilai pada berbagai fitur numerik dalam dataset.

### Melakukan pemeriksaan terhadap nilai yang hilang(missing value) pada dataset
"""

df.isnull().sum()

"""Berdasarkan hasil dari _Missing Value_, terlihat bahwa tidak ada data yang hilang atau kosong dalam dataset ini.

### Memvisualisasikan data menggunakan boxplot untuk fitur numerik:
"""

#Melihat data outlier dengan visualisasi boxplot
num_cols = len(df.select_dtypes(include=['int64']).columns)
num_rows = (num_cols + 3) // 4  # Calculate rows needed, ensuring at least 1
df.plot(kind='box', subplots=True, layout=(num_rows, 4), figsize=(15, num_rows * 4))  # Adjust figsize for better visualization
plt.tight_layout()  # Add this line to prevent overlapping of subplots
plt.show()

"""Grafik di atas memberikan gambaran distribusi data untuk berbagai variabel terkait siswa

## Exploratory Data Analysis - Univariate Analysis

Pada bagian ini kita akan melihat sebaran data pada seluruh variabel dan hubungan pada setiap variabel
"""

# Ambil semua kolom numerik
numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

# Buat histogram terpisah untuk setiap kolom
fig, axes = plt.subplots(len(numeric_cols), 1, figsize=(10, 4*len(numeric_cols)))

for i, col in enumerate(numeric_cols):
  axes[i].hist(df[col], bins=20) # Anda dapat menyesuaikan jumlah bins sesuai kebutuhan
  axes[i].set_title(f'Penyebaran Data {col}')
  axes[i].set_xlabel(col)
  axes[i].set_ylabel('Frekuensi')

plt.tight_layout()
plt.show()

"""Grafik ini memberikan gambaran umum tentang distribusi variabel-variabel terkait dengan kondisi sosial, akademik, dan kesejahteraan siswa.

## Menganalisa data menggunakan Multivariate Analysis
"""

# fitur numerik
category = df.select_dtypes(include='int64').columns.to_list()

for col in category:
  sns.catplot(x=col, y="G3", kind="bar", dodge=False, height = 4,
              aspect = 5, data=df, palette="Set3")

"""### Menampilkan Plot Pair fitur numerik"""

sns.pairplot(df, diag_kind='kde')

"""Grafik `pairplot` di atas menampilkan hubungan antar variabel dalam dataset serta distribusi masing-masing variabel secara individu

### Melakukan pengamatan terhadap tingkat korelasi dengan menggunakan matrik korelasi pada tiap fitur
"""

# Memilih hanya kolom numerik
numeric_df = df.select_dtypes(include='number')

# Membuat heatmap
plt.figure(figsize=(10, 8))
correlation_matrix = numeric_df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidth=0.5)
plt.title("Matrik Korelasi fitur numerik", size=20)

"""Heatmap ini menggambarkan korelasi antara berbagai variabel dalam dataset siswa. Dapat dilihat bahwa terdapat korelasi positif yang kuat antara pendidikan ibu (Medu) dan ayah (Fedu), yang menunjukkan kesamaan tingkat pendidikan orang tua. Korelasi negatif ditemukan antara kegagalan masa lalu dan nilai siswa (G1, G2, G3), mengindikasikan bahwa kegagalan sebelumnya berdampak pada kinerja akademik. Selain itu, nilai yang diperoleh di periode pertama (G1) memiliki korelasi tinggi dengan nilai pada periode berikutnya (G2, G3), yang menunjukkan konsistensi dalam kinerja akademik siswa.

## DATA PREPARATION

### Menghapus Data dengan Nilai G3 Kurang dari 1
"""

df.drop(df[df['G3'] < 1].index, inplace = True)

"""Kode di atas digunakan untuk menghapus semua data yang memiliki nilai kolom G3 kurang dari 1. Hal ini bertujuan untuk memastikan bahwa hanya data dengan nilai G3 yang valid dan relevan yang akan digunakan dalam analisis.

### Mengonversi Variabel Kategorikal ke Bentuk One-Hot Encoding
"""

df_ohe = pd.get_dummies(df, drop_first=True)

"""Kode ini digunakan untuk mengubah variabel kategorikal dalam dataset menjadi format one-hot encoding. Dengan drop_first=True, proses ini akan menghindari masalah multikolinearitas dengan membuang salah satu kategori referensi dari setiap variabel kategorikal."""

# Calculate the correlation matrix for all columns
correlation_matrix = df_ohe.corr()

# Extract the correlation values for the 'G3' column
correlation_with_G3 = correlation_matrix['G3']

# Create a heatmap of the correlation values
plt.figure(figsize=(5, 13))
sns.heatmap(correlation_with_G3.to_frame(), annot=True, cmap='coolwarm', linewidth=0.5)
plt.title("Matrik Korelasi Nilai G3", size=20)

"""### Menghapus Fitur dengan Korelasi Rendah"""

# Menentukan Batas Minimum Korelasi (Threshold)
THRESHOLD = 0.13

G3_corr = df_ohe.corr()["G3"]

df_ohe_after_drop_features = df_ohe.copy()

for key, value in G3_corr.items():
  if abs(value) < THRESHOLD:
    df_ohe_after_drop_features.drop(columns= key, inplace=True)

# Calculate the correlation matrix for all columns
correlation_matrix = df_ohe_after_drop_features.corr()

# Extract the correlation values for the 'G3' column
correlation_with_G3 = correlation_matrix['G3']

# Create a heatmap of the correlation values
plt.figure(figsize=(5, 13))
sns.heatmap(correlation_with_G3.to_frame(), annot=True, cmap='coolwarm', linewidth=0.5)
plt.title("Matrik Korelasi Nilai G3", size=20)

"""Perbandingan kedua grafik Matrik Korelasi di atas, menunjukkan beberapa variabel yang dihapus berdasarkan nilai `THRESHOLD` yang lebih kecil dari `0.13`. Di antaranya age, traveltime, famrel, freetime, goout, health, address_u, famsize_LE3, dan seterusnya. setelah pembersihan data ini diharapkan dapat lebih fokus pada korelasi dengan nilai yang lebih tinggi (baik positif maupun negatif)

### Membagi Dataset menjadi Fitur (X) dan Target (y)
"""

X = df_ohe_after_drop_features.drop('G3',axis = 1)
y = df_ohe_after_drop_features['G3']

df_ohe_after_drop_features.head()

"""Pada bagian ini, data dipisahkan menjadi dua bagian utama, yaitu X dan y. X merupakan kumpulan fitur independen yang berisi semua kolom dalam dataset kecuali kolom G3. Penghapusan kolom G3 dilakukan menggunakan perintah `drop('G3', axis=1)`, sehingga data yang tersisa pada X hanya mencakup fitur-fitur yang akan digunakan sebagai input untuk model machine learning. Sementara itu, y berisi kolom G3, yang merupakan variabel target atau nilai yang ingin diprediksi oleh model. Pemisahan ini penting untuk memastikan bahwa model dilatih menggunakan data fitur independen (X) untuk mempelajari hubungan atau pola yang berkaitan dengan variabel target (y).

### Membagi dataset menjadi train dan test
"""

# Dataset dibagi menjadi 80% data latih dan 20% data uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

print(f'Total of sample in whole dataset: {len(X)}')
print(f'Total of sample in train dataset: {len(X_train)}')
print(f'Total of sample in test dataset: {len(X_test)}')

"""hasil dari kode diatas dapat dilihat pada data berikut : total sampel adalah  634, dataset train adalah 507, sedangkan Total di data test adalah sebanyak 127

### Mengubah variabel target menjadi kategori
"""

X = df_ohe_after_drop_features.drop('G3',axis = 1)
y = df_ohe_after_drop_features['G3'].apply(lambda x: 'pass' if x >= 10 else 'fail')

"""Kode diatas mempersiapkan data sebelum dimasukkan ke model dengan memisahkan fitur independen (X) dan variabel target (y). Kolom G3 dihapus dari dataset untuk membentuk X, sehingga hanya berisi fitur-fitur yang akan digunakan sebagai input model. Sementara itu, kolom G3 diubah menjadi variabel kategori y yang menggunakan fungsi lambda, di mana nilai G3 diklasifikasikan sebagai 'pass' jika nilainya â‰¥ 10 dan 'fail' jika kurang dari 10. Proses ini mengubah target dari numerik menjadi kategori, sehingga data siap digunakan untuk algoritma klasifikasi seperti Logistic Regression atau Decision Tree.

## MODEL DEVELOPMENT
"""

def train_binary_classification_model(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

    model1 = LogisticRegression(max_iter=200)
    model2 = DecisionTreeClassifier()
    model3 = KNeighborsClassifier()
    model4 = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=123, n_jobs=-1, class_weight='balanced')

    models = [model1, model2, model3, model4]
    model_name_list = ['LogisticRegression', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier']

    # Dataframe for results
    results = pd.DataFrame(columns=["Test Accuracy", "Train Accuracy"], index=model_name_list)

    # Set up subplots
    fig, axes = plt.subplots(1, len(models), figsize=(20, 4))
    fig.suptitle("Confusion Matrices for Each Model")

    for i, model in enumerate(models):
        # Train the model
        model.fit(X_train, y_train)

        # Make predictions on the test set
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        # Calculate evaluation metrics
        accuracy = accuracy_score(y_test, y_test_pred)
        accuracy_train = accuracy_score(y_train, y_train_pred)

        model_name = model_name_list[i]
        results.loc[model_name, :] = [accuracy, accuracy_train]

        # Display Confusion Matrix
        cm = confusion_matrix(y_test, y_test_pred)
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, ax=axes[i])
        axes[i].set_title(f"{model_name}")
        axes[i].set_xlabel("Predicted")
        axes[i].set_ylabel("Actual")

        # Print Classification Report
        print(f"\nClassification Report for {model_name}:\n")
        print(classification_report(y_test, y_test_pred))

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

    return results

"""Kode ini merupakan sebuah fungsi untuk melatih dan mengevaluasi beberapa model klasifikasi sekaligus, dengan menampilkan metrik kinerja dan visualisasi matriks kebingungan (confusion matrix).

## EVALUASI MODEL

### Pengujuan 1
"""

results_1 = train_binary_classification_model(X,y)

"""### Pengujuan 2"""

X_all_features_except_G3 = df_ohe.drop('G3',axis = 1)
y_G3 = df_ohe ['G3'].apply(lambda x: 'pass' if x >= 10 else 'fail')

results_2 = train_binary_classification_model(X_all_features_except_G3, y_G3)

# Menambahkan label untuk setiap pengujian
results_1['Test Type'] = 'Pengujian 1'
results_2['Test Type'] = 'Pengujian 2'

# Menggabungkan hasil pengujian
comparison_table = pd.concat([results_1, results_2])
comparison_table

# Reset index agar tabel mudah diolah
comparison_table.reset_index(inplace=True)

# Grafik perbandingan
plt.figure(figsize=(10, 6))
sns.barplot(
    x='index', y='Test Accuracy', hue='Test Type', data=comparison_table
)
plt.title('Comparison of Test Accuracy Across Models')
plt.xlabel('Model')
plt.ylabel('Test Accuracy')
plt.legend(title='Test Type')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(
    x='index', y='Train Accuracy', hue='Test Type', data=comparison_table
)
plt.title('Comparison of Train Accuracy Across Models')
plt.xlabel('Model')
plt.ylabel('Train Accuracy')
plt.legend(title='Test Type')
plt.xticks(rotation=45)
plt.show()

"""## Kesimpulan

Hasil pengujian menunjukkan bahwa Logistic Regression memiliki performa paling stabil dalam kedua pengujian. Pada Pengujian 1, akurasi uji mencapai 90.55% dan akurasi pelatihan 94.48%, sedikit lebih baik dibandingkan Pengujian 2 dengan akurasi uji 88.98% dan akurasi pelatihan 96.65%. Hal ini menjadikan Logistic Regression sebagai model yang paling andal untuk generalisasi. Decision Tree dan Random Forest, meskipun memiliki akurasi uji yang cukup baik, menunjukkan indikasi overfitting karena akurasi pelatihannya selalu sempurna (100%) di kedua pengujian. Decision Tree mencatat peningkatan akurasi uji dari 88.98% pada Pengujian 1 menjadi 91.33% pada Pengujian 2, sementara Random Forest menunjukkan akurasi uji yang lebih baik pada Pengujian 1 (89.76%) dibandingkan Pengujian 2 (88.98%). KNeighborsClassifier memiliki akurasi uji yang konsisten pada kedua pengujian (88.19%), tetapi akurasi pelatihannya lebih tinggi pada Pengujian 1 (94.48%) dibandingkan Pengujian 2 (92.89%).

Secara umum, Pengujian 1 menghasilkan performa yang lebih baik pada data uji, terutama untuk Logistic Regression dan Random Forest. Logistic Regression terbukti menjadi model yang paling seimbang dalam hal akurasi uji dan pelatihan, tanpa menunjukkan tanda-tanda overfitting yang signifikan. Sebaliknya, Decision Tree dan Random Forest memerlukan penyesuaian parameter seperti max_depth atau min_samples_split untuk mengurangi overfitting dan meningkatkan generalisasi. Sementara itu, perbedaan performa antara kedua pengujian dapat mengindikasikan bahwa data tambahan pada Pengujian 2 tidak memberikan informasi yang cukup signifikan untuk meningkatkan kinerja model secara keseluruhan.
"""